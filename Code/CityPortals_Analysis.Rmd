---
title: "City Open Data Portals and Library Data"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

```{r}
# Load relevant libraries
library(dplyr)
library(Hmisc)
#library(summarytools)
library(tidyr)
library(splitstackshape)
library(httr)
```

```{r}
token <- read.delim("~/Google Drive File Stream/My Drive/Keys/g_access.txt", stringsAsFactor = FALSE, header = FALSE)
```

```{r}
# Read in portals data stored in private github repository
url=paste0("https://raw.githubusercontent.com/OpenDataLiteracy/JCDL-Extended/master/Data/KAS_JCDL_PrelimClean_2019-12-16.csv")
x=GET(url, add_headers(Authorization = paste("token", token, sep = " ")))
portals <- content(x, type="text/csv", encoding = "UTF-8")
```

```{r}
# Read in IMLS data stored in private github repository
url=paste0("https://raw.githubusercontent.com/OpenDataLiteracy/JCDL-Extended/master/Data/IMLS_Data_PLS_FY17_AE_pud17i.csv")
x=GET(url, add_headers(Authorization = paste("token", token, sep = " ")))
imls <- content(x, type="text/csv", encoding = "UTF-8")
```

```{r}
# Read in IMLS data stored in private github repository
url=paste0("https://raw.githubusercontent.com/OpenDataLiteracy/JCDL-Extended/master/Data/PLS_FY17_Outlet_pud17i.csv")
x=GET(url, add_headers(Authorization = paste("token", token, sep = " ")))
imls_outlet <- content(x, type="text/csv", encoding = "UTF-8")
```

```{r}
# Removed random additional column in portals dataset
portals <- portals %>% select(-X13)
# Fix date formats
portals$DateLibDataLastUpdated <- as.Date(portals$DateLibDataLastUpdated, format = "%Y-%m-%d")
portals$DatePortalAccessed <- as.Date(portals$DatePortalAccessed, format = "%Y-%m-%d")
# Variables to datatype character
portals$Portal_URL <- as.character(portals$Portal_URL)
```

```{r}
# Split into individual categories and create dummy variables.
portals <- cSplit_e(portals, split.col = "LibraryDataCategories", sep = ",", type = "character", 
         mode = "binary", fixed = TRUE, fill = 0)
```

```{r}
# Calculate (and add column) the percentage of the city portal data that is public library related
portals$ProportionPublicLibData <- portals$CountVettedPublicLibData / portals$TotalDataSetsAvailable
```

```{r} 
# Fix different capitalizations
portals <- portals %>%
       mutate(City = tolower(City),
              State = tolower(State))

imls <- imls %>%
       mutate(CITY = tolower(CITY),
              STABR = tolower(STABR))

# Merge datasets on city, state
temp <- merge(portals, imls, by.x = c("City", "State"), by.y = c("CITY", "STABR"), all.x = TRUE)
```

```{r}
merged <- merge(temp, imls_outlet, by = "LIBNAME", all.x = TRUE)
```

```{r}
# Variables to datatype factor
# jcdl$Locale <- as.factor(jcdl$Locale)
# jcdl$ReportingStatus <- as.factor(jcdl$ReportingStatus)
# jcdl$MailingZip <- as.factor(jcdl$MailingZip)
# jcdl$Year <- as.factor(jcdl$Year)
```

```{r}
# Check unique values
unique(merged$Software)
```

```{r}
# See what values we have for Locale
unique(merged$LOCALE)
```

```{r}
# Create a LocaleDescr column and fill based on condition
merged <- merged %>% 
    mutate(LocaleDescr = case_when(
                LOCALE == 11 ~ "City Large",
                LOCALE == 12 ~ "City Midsize",
                LOCALE == 13 ~ "City Small",
                LOCALE == 21 ~ "Suburban Large",
                LOCALE == 22 ~ "Suburban Midsize",
                LOCALE == 23 ~ "Suburban Small",
                LOCALE == 31 ~ "Town Fringe",
                LOCALE == 32 ~ "Town Distant",
                LOCALE == 33 ~ "Town Remote",
                LOCALE == 41 ~ "Rural Fringe",
                LOCALE == 42 ~ "Rural Distant",
                LOCALE == 43 ~ "Rural Remote"
))
```


```{r}
# Change datatype of LocaleDescr
merged$LocaleDescr <- as.factor(merged$LocaleDescr)
```

```{r}
# Uncomment this to view a nice table of descriptive stats in the Viewer
#view(dfSummary(jcdl))
```

```{r}
# Uncomment for descriptive stats
#Hmisc::describe(jcdl)
```

```{r}
# Simple linear regression model
jcdl_PropLR <- lm(ProportionPublicLibData ~ OpenDataCensusScores, data=jcdl)
summary(jcdl_PropLR)
```

```{r}
# Simple linear regression model
jcdl_VettLR <- lm(CountVettedPublicLibData ~ OpenDataCensusScores, data=jcdl)
summary(jcdl_VettLR)
```

```{r}
# Simple linear regression model
jcdl_TotLR <- lm(TotalDatasetsAvailable ~ OpenDataCensusScores, data=jcdl)
summary(jcdl_TotLR)
```

```{r}
# Simple linear regression model
jcdl_PropSizeLR <- lm(ProportionPublicLibData ~ LocaleDescr, data=jcdl)
summary(jcdl_PropSizeLR)
```

```{r}
# Simple linear regression model
jcdl_VettSizeLR <- lm(CountVettedPublicLibData ~ LocaleDescr, data=jcdl)
summary(jcdl_VettSizeLR)
```

```{r}
# Simple linear regression model
jcdl_TotSizeLR <- lm(TotalDatasetsAvailable ~ LocaleDescr, data=jcdl)
summary(jcdl_TotSizeLR)
```
```{r}
# Simple linear regression model
jcdl_TotRevCityLR <- lm(TotalDatasetsAvailable ~ TotalRevenue, data=jcdl)
summary(jcdl_TotRevCityLR)
```


```{r}
# Simple linear regression model
jcdl_TotRevLR <- lm(CountVettedPublicLibData ~ TotalRevenue, data=jcdl)
summary(jcdl_TotRevLR)
```

```{r}
# Simple linear regression model
jcdl_TotStaffLR <- lm(CountVettedPublicLibData ~ TotalStaff, data=jcdl)
summary(jcdl_TotStaffLR)
```

```{r}
# Create temporary matrix to use in Pearson's correlation
x <- jcdl %>% select(TotalRevenue, TotalStaff)
x$TotalRevenue <- as.numeric(x$TotalRevenue)

```

```{r}
# Calculate Pearson's correlation
cor(x)
```


```{r}
# Run (simple) LM dependent variable ProportionPublicLibData against all 
# possible numeric columns

# Adapted from https://stackoverflow.com/questions/30583917/regression-loop-in-r-for-data-frames

for(i in names(jcdl))
{ 
    if(is.numeric(jcdl[,i]))  ##if column is numeric run regression
    {       
       fit <- lm(ProportionPublicLibData ~ jcdl[,i], data=jcdl) 
       coeff <- summary(fit)$coefficients[,4][2] #output only the p-values
       writeLines(paste(coeff,i,"\n"))
    }
}
```

```{r}
# Run (simple) LM dependent variable CountVettedPublicLibData against all 
# possible numeric columns

# Adapted from https://stackoverflow.com/questions/30583917/regression-loop-in-r-for-data-frames

for(i in names(jcdl))
{ 
    if(is.numeric(jcdl[,i]))  ##if column is numeric run regression
    {       
       fit <- lm(CountVettedPublicLibData ~ jcdl[,i], data=jcdl) 
       coeff <- summary(fit)$coefficients[,4][2] #output only the p-values
       writeLines(paste(coeff,i,"\n"))
    }
}
```

```{r}
library(reshape2)
dfm <- melt(jcdl[,c('LibraryDataCategories_catalogandcirculation','LibraryDataCategories_eventscalendar',
                    'LibraryDataCategories_facilities', 'LibraryDataCategories_financial',
                    'LibraryDataCategories_geospatial', 'LibraryDataCategories_patrons',
                    'LibraryDataCategories_publicrecords', 'LibraryDataCategories_technologyofferings',
'LibraryDataCategories_utilities')])
```
```{r}
# total datasets by category
dfm <- dfm %>% group_by(variable) %>% summarise("total" = sum(value))
```

```{r}
# barchart of datset totals by category
p <- ggplot(dfm, aes(variable, total)) +
  geom_bar(stat="identity", fill="steelblue") +
  scale_x_discrete(labels=c("LibraryDataCategories_catalogandcirculation" = "Catalog & Circulation",
                            "LibraryDataCategories_eventscalendar" = "Events & Calendar",
                            "LibraryDataCategories_facilities" = "Facilities",
                            "LibraryDataCategories_financial" = "Financial",
                            "LibraryDataCategories_geospatial" = "Geospatial",
                            "LibraryDataCategories_patrons" = "Patrons",
                            "LibraryDataCategories_publicrecords" = "Public Records",
                            "LibraryDataCategories_technologyofferings" = "Technology Offerings",
                            "LibraryDataCategories_utilities" = "Utilities")) +
  theme(axis.text.x = element_text(angle = 75, hjust = 1)) +
  geom_text(aes(label=total), vjust=1.6, color="white", size=3.5) +
  xlab("Dataset Category") +
  ylab("Datasets Available")
p
ggsave("~/Google Drive File Stream/My Drive/ODL/JCDL/categories_barchart.png")
```

```{r}
# same barcgart as above but arranged in descending order of dataset count
p <- ggplot(dfm, aes(x = reorder(variable, -total), total)) +
  geom_bar(stat="identity", fill="steelblue") +
  scale_x_discrete(labels=c("LibraryDataCategories_catalogandcirculation" = "Catalog & Circulation",
                            "LibraryDataCategories_eventscalendar" = "Events & Calendar",
                            "LibraryDataCategories_facilities" = "Facilities",
                            "LibraryDataCategories_financial" = "Financial",
                            "LibraryDataCategories_geospatial" = "Geospatial",
                            "LibraryDataCategories_patrons" = "Patrons",
                            "LibraryDataCategories_publicrecords" = "Public Records",
                            "LibraryDataCategories_technologyofferings" = "Technology Offerings",
                            "LibraryDataCategories_utilities" = "Utilities")) +
  theme(axis.text.x = element_text(angle = 75, hjust = 1)) +
  geom_text(aes(label=total), vjust=-0.4, color="black", size=3.5) +
  xlab("Dataset Category") +
  ylab("Datasets Available")
p
ggsave("~/Google Drive File Stream/My Drive/ODL/JCDL/categories_barchart_sorted.png")
```

```{r}
nrow(jcdl[jcdl$CountVettedPublicLibData > 0,])
length(jcdl$CountVettedPublicLibData[jcdl$CountVettedPublicLibData > 0])
sum(which(jcdl$CountVettedPublicLibData > 0))
```

```{r}
# Create df with just necessary columns and rows where CountVettedPublicLibData is greater than 0
no_ds <- jcdl %>%
  select(City, State, Software, TotalDatasetsAvailable, CountVettedPublicLibData, ProportionPublicLibData) %>%
  filter(CountVettedPublicLibData > 0)
```

```{r}
# barchart of cities with more than 1 library dataset
no_ds2 <- filter(no_ds, CountVettedPublicLibData > 1)
p1 <- ggplot(no_ds2, aes(City, CountVettedPublicLibData)) +
  geom_bar(stat="identity", fill="steelblue") +
  theme(axis.text.x = element_text(angle = 75, hjust = 1)) +
  xlab("City") +
  ylab("Datasets Available") 
p1
#ggsave("~/Google Drive File Stream/My Drive/ODL/JCDL/cities_barchart.png")
```

```{r}
# sorted barchart of cities with more than 1 library dataset
p1 <- ggplot(no_ds2, aes(x = reorder(City, -CountVettedPublicLibData), CountVettedPublicLibData)) +
  geom_bar(stat="identity", fill="steelblue") +
  theme(axis.text.x = element_text(angle = 75, hjust = 1)) +
  geom_text(aes(label=CountVettedPublicLibData), vjust=-0.4, color="black", size=3.5) +
  xlab("City") +
  ylab("Datasets Available") 
p1
ggsave("~/Google Drive File Stream/My Drive/ODL/JCDL/cities_barchart_sorted_morethanone.png")
```

```{r, fig.width=10, fig.height=4}
df1 <- data.frame(jcdl$TotalRevenue/10000000, jcdl$CountVettedPublicLibData, jcdl$City)
df2 <- melt(df1, id.vars='jcdl.City')
head(df2)


ggplot(df2, aes(x=jcdl.City, y=value, fill=variable)) +
    geom_bar(stat='identity', position='dodge')+
  theme(axis.text.x = element_text(angle = 75, hjust = 1))
```


```{r}
p1 <- ggplot(jcdl, aes(City, TotalRevenue)) +
  geom_bar(stat="identity", fill="steelblue") +
  theme(axis.text.x = element_text(angle = 75, hjust = 1)) +
  xlab("City") +
  ylab("Total Library Revenue") 
p1
ggsave("~/Google Drive File Stream/My Drive/ODL/JCDL/cities_revenue_barchart.png")
```

```{r}
jcdl %>%
  select(City, CountVettedPublicLibData) %>%
  arrange(desc(CountVettedPublicLibData))
```

```{r}
jcdl %>%
  select(City, OpenDataCensusScores) %>%
  arrange(desc(OpenDataCensusScores))
```