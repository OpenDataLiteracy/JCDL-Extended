---
title: "City Open Data Portals and Library Data"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

```{r}
options(scipen=999)
```

```{r}
# Load relevant libraries
library(dplyr)
library(tidyr)
library(splitstackshape)
library(httr)
library(ggplot2)
library(visdat)
```

```{r}
# retrieve token needed to access data in private github repository
token <- read.delim("~/Google Drive File Stream/My Drive/Keys/g_access.txt", stringsAsFactor = FALSE, header = FALSE)
```

```{r}
# Read in portals data stored in private github repository
url=paste0("https://raw.githubusercontent.com/OpenDataLiteracy/JCDL-Extended/master/Data/KAS_JCDL_PrelimClean_2019-12-16.txt")
x=GET(url, add_headers(Authorization = paste("token", token, sep = " ")))
portals <- content(x, type="text/tab-separated-values", encoding = "UTF-8")
as.data.frame(portals)
```

```{r}
# Remove pittsburgh from dataset - the portal is not limited to the city of pittsburgh
portals <- portals %>%
  filter(City != "Pittsburgh")
```

```{r}
# Read in IMLS Administrative Entities data stored in private github repository
url=paste0("https://raw.githubusercontent.com/OpenDataLiteracy/JCDL-Extended/master/Data/IMLS_Data_PLS_FY17_AE_pud17i.csv")
x=GET(url, add_headers(Authorization = paste("token", token, sep = " ")))
imls <- content(x, type="text/csv", encoding = "UTF-8")
as.data.frame(imls)
```


```{r}
# How many distinct cities do we have?
portals %>%
  select(City, State) %>%
  n_distinct()
```

```{r}
# How many rows of each type of software?
portals %>%
  count(Software)
```

**AE** refers to **administrative entity**: "the agency that is legally established under local or state law to provide public library service to the population of a local jurisdiction. [In the PLS] the terms **public library** and **public library system** mean an AE. The AE may have a single outlet or multiple outlets." 

```{r}
# Fix date formats
portals$DateLibDataLastUpdated <- as.Date(portals$DateLibDataLastUpdated, format = "%Y-%m-%d")
portals$DatePortalAccessed <- as.Date(portals$DatePortalAccessed, format = "%Y-%m-%d")
# Designate variables as factor
portals$LibraryDataCategories <- as.factor(portals$LibraryDataCategories)
portals$Software <- as.factor(portals$Software)
# Replace N/A with na
portals$OpenDataCensusScore2017 <- ifelse(portals$OpenDataCensusScore2017 != "N/A", portals$OpenDataCensusScore2017, NA)
# Variables to numeric
portals$OpenDataCensusScore2017 <- as.numeric(portals$OpenDataCensusScore2017)
```

```{r}
# What cities have more than 0 library datasets
portals %>%
  group_by(City, State) %>%
  filter(CountVettedPublicLibData > 0)
```

```{r}
# how many cities have more than 0 library datasets (in case New Orleans shows up twice)
portals %>%
  group_by(City, State) %>%
  filter(CountVettedPublicLibData > 0) %>%
  select(City, State) %>%
  n_distinct()
```

```{r}
# How many library datasets exist in the data?
portals %>%
  summarise(sum(CountVettedPublicLibData, na.rm = T))
```

```{r}
# Split categories into individual categories based on comma delineation, then create dummy variables.
portals <- cSplit_e(portals, split.col = "LibraryDataCategories", sep = ";", type = "character", 
         mode = "binary", fixed = TRUE, fill = 0)
```

```{r}
# Calculate (and add column) the percentage of the city portal data that is public library related
portals$ProportionPublicLibData <- portals$CountVettedPublicLibData / portals$TotalDataSetsAvailable
```

```{r}
# Count how many portals are included in the individual cities add colum to dataframe
portals <- portals %>%
  add_count(City, State, name = "CountPortalsinCity")
```

```{r}
# Which cities have more than one portal?
portals %>%
  filter(CountPortalsinCity > 1)
```

New Orleans is the only city in the dataset that has more than one portal for the city.

```{r}
#write.csv(portals, "~/Documents/Github/JCDL-Extended/Data/CityPortals_CategoryDummies")
```

```{r} 
# Fix different capitalizations
portals <- portals %>%
       mutate(City = tolower(City),
              State = tolower(State))

imls <- imls %>%
       mutate(CITY = tolower(CITY),
              STABR = tolower(STABR))

# Merge datasets on city, state
merged <- merge(portals, imls, by.x = c("City", "State"), by.y = c("CITY", "STABR"), all.x = TRUE)
```

```{r}
# how many library datasets there are per distinct city
#reference: https://stackoverflow.com/a/58653393/5593458
portals %>%
  group_by(City, State) %>%
  summarise(Total_CountVettedPublicLibData = sum(CountVettedPublicLibData)) %>%
  tidyr::unite(CityState, City, State, sep = " ", remove = F, na.rm = F) # this creates a new column with city and state combined
```

```{r}
portals %>%
  group_by(City, State) %>%
  summarise(Total_CountVettedPublicLibData = sum(CountVettedPublicLibData)) %>%
  tidyr::unite(CityState, City, State, sep = " ", remove = F, na.rm = F) %>%
  ggplot(aes(CityState, Total_CountVettedPublicLibData)) +
    geom_bar(stat="identity", fill="steelblue") +
    theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust=0.4, size = 4)) +
    xlab("City State") +
    ylab("Library Datasets Available on City Portal") 
#ggsave("~/Documents/Github/JCDL-Extended/Images/cities_barchart.png")
```

```{r}
portals %>%
  group_by(City, State) %>%
  summarise(Total_CountVettedPublicLibData = sum(CountVettedPublicLibData)) %>%
  tidyr::unite(CityState, City, State, sep = " ", remove = F, na.rm = F) %>%
  ggplot(aes(reorder(CityState, -Total_CountVettedPublicLibData), Total_CountVettedPublicLibData)) +
    geom_bar(stat="identity", fill="steelblue") +
    theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust=0.4, size = 4)) +
    geom_text(aes(label=Total_CountVettedPublicLibData), vjust=-0.4, color="black", size=2) +
    xlab("City State") +
    ylab("Library Datasets Available on City Portal") 
#ggsave("~/Documents/Github/JCDL-Extended/Images/cities_barchart_sorted.png")
```

```{r}
portals %>%
  group_by(City, State) %>%
  summarise(Total_CountVettedPublicLibData = sum(CountVettedPublicLibData)) %>%
  filter(Total_CountVettedPublicLibData > 0) %>%
  tidyr::unite(CityState, City, State, sep = " ", remove = F, na.rm = F) %>%
  ggplot(aes(reorder(CityState, -Total_CountVettedPublicLibData), Total_CountVettedPublicLibData)) +
    geom_bar(stat="identity", fill="steelblue") +
    theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust=0.4, size = 9)) +
    geom_text(aes(label=Total_CountVettedPublicLibData), vjust=-0.4, color="black", size=3) +
    xlab("City State") +
    ylab("Library Datasets Available on City Portal") 
#ggsave("~/Documents/Github/JCDL-Extended/Images/cities_barchart_sorted_no_zeroes.png")
```

```{r}
portals %>% tidyr::pivot_longer(
  cols = c('LibraryDataCategories_CatalogAndCirculation',
           'LibraryDataCategories_EventsAndOutreach',
           'LibraryDataCategories_FacilitiesAndGeospatial',
           'LibraryDataCategories_Financial',
           'LibraryDataCategories_HumanResources',
           'LibraryDataCategories_Patrons',
           'LibraryDataCategories_PublicRecords',
           'LibraryDataCategories_TechnologyOfferings'),
  names_to = "Category",
  values_to = "Total") %>%
  group_by(Category) %>% 
  summarise("GrandTotal" = sum(Total)) %>%
  ggplot(aes(Category, GrandTotal)) +
    geom_bar(stat="identity", fill="steelblue") +
    theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust=0.4, size = 9)) +
    geom_text(aes(label=GrandTotal), vjust=1.1, color="white", size=3) +
    xlab("Data Category") +
    ylab("Total Count") 

#ggsave("~/Documents/Github/JCDL-Extended/Images/categories_barchart.png")

```


```{r}
# Check unique values
unique(merged$Software)
```

```{r}
# See what values we have for geocodes
unique(merged$GEOCODE)
```

```{r}
# See what values we have for Locale_add
unique(merged$LOCALE_ADD)
```

```{r}
# See what values we have for Locale_mod
unique(merged$LOCALE_MOD)
```

Definitions of LOCALE features see PLS Data File Documentation (https://www.imls.gov/sites/default/files/fy2017_pls_data_file_documentation.pdf) page 23 reproduced below:

Locale codes allow users to identify whether AEs and library outlets are in cities, suburbs, towns, or rural areas. Locale codes were assigned to AEs and outlets using the 2017 NCES locale framework. Locale codes for AEs were assigned using two methodologies:

1. Based on geocoded latitude and longitude values of the AE's street addresses
2. Based on the modal locale codes of the central and branch libraries of that library system (excluding bookmobile and books-by-mail-only outlets). Whenever there was a tie in modal code, the AE retained its prior year locale code, if that code was among the tied values. If the tie involved locale codes that were different from the locale code corresponding to the AE's prior locale copde, the most urban code of the ties locale codes was assigned to that AE.

Locale codes for outlets were assigned based on geocoded latitude and longitude of the outlet's street address.

```{r}
# Create a Description column for both LOCALE_ADD and LOCALE_MOD and fill based on condition
merged <- merged %>% 
    mutate(LOCALE_ADD_DESCR = case_when(
                LOCALE_ADD == 11 ~ "City Large",
                LOCALE_ADD == 12 ~ "City Midsize",
                LOCALE_ADD == 13 ~ "City Small",
                LOCALE_ADD == 21 ~ "Suburban Large",
                LOCALE_ADD == 22 ~ "Suburban Midsize",
                LOCALE_ADD == 23 ~ "Suburban Small",
                LOCALE_ADD == 31 ~ "Town Fringe",
                LOCALE_ADD == 32 ~ "Town Distant",
                LOCALE_ADD == 33 ~ "Town Remote",
                LOCALE_ADD == 41 ~ "Rural Fringe",
                LOCALE_ADD == 42 ~ "Rural Distant",
                LOCALE_ADD == 43 ~ "Rural Remote"),
           LOCALE_MOD_DESCR = case_when(
                LOCALE_MOD == 11 ~ "City Large",
                LOCALE_MOD == 12 ~ "City Midsize",
                LOCALE_MOD == 13 ~ "City Small",
                LOCALE_MOD == 21 ~ "Suburban Large",
                LOCALE_MOD == 22 ~ "Suburban Midsize",
                LOCALE_MOD == 23 ~ "Suburban Small",
                LOCALE_MOD == 31 ~ "Town Fringe",
                LOCALE_MOD == 32 ~ "Town Distant",
                LOCALE_MOD == 33 ~ "Town Remote",
                LOCALE_MOD == 41 ~ "Rural Fringe",
                LOCALE_MOD == 42 ~ "Rural Distant",
                LOCALE_MOD == 43 ~ "Rural Remote")
           )
```

```{r}
# Change datatype of LOCALE DESCRs
merged$LOCALE_ADD_DESCR <- as.factor(merged$LOCALE_ADD_DESCR)
merged$LOCALE_MOD_DESCR <- as.factor(merged$LOCALE_MOD_DESCR)
```

```{r}
# Find out which cities have more than one AE  
merged %>%
  count(City, State, Portal_URL, sort = T) %>%
  #Portal_URL is used to differentiate cities that have multiple data portals but only one library system
  filter(n > 1)
```

15 cities have more than one library system. New Orleans is not included in these results but has two rows in the data because it has two city data portals.

```{r}
# Count how many AEs are included in the individual cities add colum to dataframe
merged <- merged %>%
  add_count(City, State, Portal_URL, name = "CountAEinCity") 
#Portal_URL is used to differentiate cities that have multiple data portals but only one library system
```

```{r}
# Create a separate dataframe for those with multiple AEs
multi_libs <- merged %>%
  filter(CountAEinCity > 1)

write.csv(multi_libs, "~/Documents/Github/JCDL-Extended/Data/Cities_with_multiple_admin_entities")
```

```{r}
# Create a separate dataframe for those with only one AE
single_libs <- merged %>%
  filter(CountAEinCity == 1)
```

```{r}
# Use this code to visualize missing data (probably best at 10 columns at a time)
visdat::vis_miss(single_libs[1:10])
```


```{r}
# Simple linear regression model
single_libs_PropLR <- lm(ProportionPublicLibData ~ OpenDataCensusScore2017, data=single_libs)
summary(single_libs_PropLR)
```

There doesn't appear to be a strong relationship between the proportion of data in a city portal that is library data and the Open Data Census score from 2017.

```{r}
# Simple linear regression model
single_libs_VettLR <- lm(CountVettedPublicLibData ~ OpenDataCensusScore2017, data=single_libs)
summary(single_libs_VettLR)
```

There may be a positive relationship between number of library datasets available in a city portal and the Open Data Census score from 2017 but it's not a great fit. 

```{r}
plot(single_libs_VettLR)
```

Could try log of Count because it's heavily right-skewed:

```{r}
# Simple linear regression model
single_libs_VettLR_log <- lm(log(CountVettedPublicLibData + 0.0000001) ~ OpenDataCensusScore2017, data=single_libs)
summary(single_libs_VettLR_log)
```

Now it appears that there is not a relationship between the two variables.

```{r}
# Simple linear regression model
single_libs_TotLR <- lm(TotalDataSetsAvailable ~ OpenDataCensusScore2017, data=single_libs)
summary(single_libs_TotLR)
```

Now we see a statistically significant relationship between the total number of datasets available in a city portal and the Open Data Census score from 2017. The R-squared isn't great so we can check the residuals and qq plot. But a positive relationship between these two variables would not be surprising.

```{r}
plot(single_libs_TotLR)
```

```{r}
single_libs %>% 
  ggplot(aes(TotalDataSetsAvailable, OpenDataCensusScore2017)) +
  geom_point()

```


```{r}
# Simple linear regression model
single_libs_PropSizeLR <- lm(ProportionPublicLibData ~ LOCALE_ADD_DESCR, data=single_libs)
summary(single_libs_PropSizeLR)
```

There doesn't appear to be a relationship between the proportion of public library data in a city portal and the Locale code.

```{r}
# Simple linear regression model
single_libs_VettSizeLR <- lm(CountVettedPublicLibData ~ LOCALE_ADD_DESCR, data=single_libs)
summary(single_libs_VettSizeLR)
```

There doesn't appear to be a relationship between the count of public library data in a city portal and the Locale code.

```{r}
# Simple linear regression model
single_libs_TotSizeLR <- lm(TotalDataSetsAvailable ~ LOCALE_ADD_DESCR, data=single_libs)
summary(single_libs_TotSizeLR)
```

There doesn't appear to be a relationship between the count of total datasets in a city portal and the Locale code.

```{r}
# Simple linear regression model total datasets avail and total operating revenue
single_libs_TotRevCityLR <- lm(TotalDataSetsAvailable ~ TOTINCM, data=single_libs)
summary(single_libs_TotRevCityLR)
```

Here we have a statistically significant relationship between the total number of datasets available in a city portal and the Total Operating Revenue (sum of LOCGVT, STGVT, FEDGVT, and OTHINCM). The R-squared isn't great so we can check the residuals and qq plot.

```{r}
plot(single_libs_TotRevCityLR)
```

```{r}
single_libs %>% 
  ggplot(aes(TotalDataSetsAvailable, TOTINCM)) +
  geom_point() +
  scale_x_log10() +
  scale_y_log10() 
```

```{r}
# Simple linear regression model total datasets avail and total operating revenue
single_libs_TotRevCityLR_log <- lm(log10(TotalDataSetsAvailable + 0.0000001) ~ log10(TOTINCM + 0.0000001), data=single_libs)
summary(single_libs_TotRevCityLR_log)
```

```{r}
plot(single_libs_TotRevCityLR_log)
```

There's a much stronger relationship between the logged values of total datasets and income, but the residuals are still not evenly distributed.

```{r}
# Simple linear regression model
single_libs_TotRevLR <- lm(CountVettedPublicLibData ~ TOTINCM, data=single_libs)
summary(single_libs_TotRevLR)
```

```{r}
# Simple linear regression model
single_libs_TotStaffLR <- lm(CountVettedPublicLibData ~ TOTSTAFF, data=single_libs)
summary(single_libs_TotStaffLR)
```

```{r}
# Create temporary matrix to use in Pearson's correlation
x <- single_libs %>% select(TOTINCM, TOTSTAFF)
x$TOTINCM <- as.numeric(x$TOTINCM)

```

```{r}
# Calculate Pearson's correlation
cor(x, use = "complete.obs")
```


```{r}
# Run (simple) LM dependent variable ProportionPublicLibData against all 
# possible numeric columns

# Adapted from https://stackoverflow.com/questions/30583917/regression-loop-in-r-for-data-frames
# Also indexing tibbles is weird - hence the double brackets. See https://twitter.com/kara_woo/status/1218297608289996800

x <- names(single_libs)

for(i in x)
{ 
    if(is.numeric(single_libs[[i]]))  ##if column is numeric run regression
    {
      fit <- lm(ProportionPublicLibData ~ single_libs[[i]], data=single_libs) 
      coeff <- summary(fit)$coefficients[,4][2] #output only the p-values
      rsq <- summary(fit)$r.squared
      if(!is.na(coeff) & coeff < 0.1) {writeLines(paste(coeff,i,rsq,"\n"))}
    }
}
```

```{r}
# Run (simple) LM dependent variable CountVettedPublicLibData against all 
# possible numeric columns

# Adapted from https://stackoverflow.com/questions/30583917/regression-loop-in-r-for-data-frames
# Also indexing tibbles is weird - hence the double brackets. See https://twitter.com/kara_woo/status/1218297608289996800

for(i in x)
{ 
  if(is.numeric(single_libs[[i]]))  ##if column is numeric run regression
    {       
       fit <- lm(CountVettedPublicLibData ~ single_libs[[i]], data=single_libs) 
       coeff <- summary(fit)$coefficients[,4][2] #output only the p-values
       rsq <- summary(fit)$r.squared
       if(!is.na(coeff) & coeff < 0.1) {writeLines(paste(coeff,i,rsq,"\n"))}
    }
}
```

```{r}
dfm <- reshape2::melt(single_libs[,c('LibraryDataCategories_CatalogAndCirculation','LibraryDataCategories_EventsAndOutreach',
                    'LibraryDataCategories_FacilitiesAndGeospatial', 'LibraryDataCategories_Financial',
                    'LibraryDataCategories_HumanResources', 'LibraryDataCategories_Patrons',
                    'LibraryDataCategories_PublicRecords', 'LibraryDataCategories_TechnologyOfferings')])
```

```{r}
# total datasets by category
dfm <- dfm %>% group_by(variable) %>% summarise("total" = sum(value))
```

```{r}
# barchart of datset totals by category
p <- ggplot(dfm, aes(variable, total)) +
  geom_bar(stat="identity", fill="steelblue") +
  scale_x_discrete(labels=c("LibraryDataCategories_CatalogAndCirculation" = "Catalog & Circulation",
                            "LibraryDataCategories_EventsAndOutreach" = "Events & Outreach",
                            "LibraryDataCategories_FacilitiesAndGeospatial" = "Facilities & Geospatial",
                            "LibraryDataCategories_Financial" = "Financial",
                            "LibraryDataCategories_HumanResources" = "Human Resources",
                            "LibraryDataCategories_Patrons" = "Patrons",
                            "LibraryDataCategories_PublicRecords" = "Public Records",
                            "LibraryDataCategories_TechnologyOfferings" = "Technology Offerings")) +
  theme(axis.text.x = element_text(angle = 75, hjust = 1)) +
  geom_text(aes(label=total), vjust=1.6, color="white", size=3.5) +
  xlab("Dataset Category") +
  ylab("Datasets Available")
p
#ggsave("~/Documents/Github/JCDL-Extended/Images/single_libs_categories_barchart.png")
```

```{r}
# same barchart as above but arranged in descending order of dataset count
p <- ggplot(dfm, aes(x = reorder(variable, -total), total)) +
  geom_bar(stat="identity", fill="steelblue") +
  scale_x_discrete(labels=c("LibraryDataCategories_CatalogAndCirculation" = "Catalog & Circulation",
                            "LibraryDataCategories_EventsAndOutreach" = "Events & Outreach",
                            "LibraryDataCategories_FacilitiesAndGeospatial" = "Facilities & Geospatial",
                            "LibraryDataCategories_Financial" = "Financial",
                            "LibraryDataCategories_HumanResources" = "Human Resources",
                            "LibraryDataCategories_Patrons" = "Patrons",
                            "LibraryDataCategories_PublicRecords" = "Public Records",
                            "LibraryDataCategories_TechnologyOfferings" = "Technology Offerings")) +
  theme(axis.text.x = element_text(angle = 75, hjust = 1)) +
  geom_text(aes(label=total), vjust=-0.4, color="black", size=3.5) +
  xlab("Dataset Category") +
  ylab("Datasets Available")
p
#ggsave("~/Documents/Github/JCDL-Extended/Images/single_libs_categories_barchart_sorted.png")
```

```{r}
nrow(single_libs[single_libs$CountVettedPublicLibData > 0,])
length(single_libs$CountVettedPublicLibData[single_libs$CountVettedPublicLibData > 0])
sum(which(single_libs$CountVettedPublicLibData > 0))
```

```{r}
# Create df with just necessary columns and rows where CountVettedPublicLibData is greater than 0
no_ds <- single_libs %>%
  select(City, State, Software, TotalDataSetsAvailable, CountVettedPublicLibData, ProportionPublicLibData) %>%
  filter(CountVettedPublicLibData > 0)
```

```{r}
# barchart of cities with more than 1 library dataset
no_ds2 <- filter(no_ds, CountVettedPublicLibData > 1)
p1 <- ggplot(no_ds2, aes(City, CountVettedPublicLibData)) +
  geom_bar(stat="identity", fill="steelblue") +
  theme(axis.text.x = element_text(angle = 75, hjust = 1)) +
  xlab("City") +
  ylab("Datasets Available") 
p1
#ggsave("~/Documents/Github/JCDL-Extended/Images/single_libs_cities_barchart.png")
```

```{r}
# sorted barchart of cities with more than 1 library dataset
p1 <- ggplot(no_ds2, aes(x = reorder(City, -CountVettedPublicLibData), CountVettedPublicLibData)) +
  geom_bar(stat="identity", fill="steelblue") +
  theme(axis.text.x = element_text(angle = 75, hjust = 1)) +
  geom_text(aes(label=CountVettedPublicLibData), vjust=-0.4, color="black", size=3.5) +
  xlab("City") +
  ylab("Datasets Available") 
p1
#ggsave("~/Documents/Github/JCDL-Extended/Images/single_libs_cities_barchart_sorted_no_zeroes.png")
```

```{r, fig.width=10, fig.height=4}
df1 <- data.frame(single_libs$TOTINCM/10000000, single_libs$CountVettedPublicLibData, single_libs$City)
df2 <- reshape2::melt(df1, id.vars='single_libs.City')
head(df2)


ggplot(df2, aes(x=single_libs.City, y=value, fill=variable)) +
    geom_bar(stat='identity', position='dodge')+
  theme(axis.text.x = element_text(angle = 75, hjust = 1))
```


```{r}
p1 <- ggplot(single_libs, aes(City, TOTINCM)) +
  geom_bar(stat="identity", fill="steelblue") +
  theme(axis.text.x = element_text(angle = 75, hjust = 1)) +
  xlab("City") +
  ylab("Total Library Revenue") 
p1
#ggsave("~/Documents/Github/JCDL-Extended/Images/cities_revenue_barchart.png")
```

```{r}
single_libs %>%
  select(City, CountVettedPublicLibData) %>%
  arrange(desc(CountVettedPublicLibData))
```

```{r}
single_libs %>%
  select(City, OpenDataCensusScore2017) %>%
  arrange(desc(OpenDataCensusScore2017))
```

```{r}
skimr::skim(single_libs)
```

